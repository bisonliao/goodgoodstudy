# 架构检查点

## 0、谁最牛？

行业最高水平在哪里？ 有没有可复用的？熟悉相关的成熟方案和常用组件，包括公有云

事情的难点在哪里？高高手怎么解决的？

## 1、可扩展性

网络协议：例如PB协议

数据结构：例如json相比c中的结构体

平行扩展能力：简单增加机器就可以线性扩展性能和容量

逻辑分层、概念抽象和封装：例如linux的文件系统的抽象

## 2、高性能

量化，目标和分析都用数据说话，明确关键路径和瓶颈位置

设计容量评估与分解：多少用户量？多少请求量？每个模块的资源瓶颈是什么（CPU/内存量/磁盘IO/带宽/包量）？路由中各级网络带宽和包量是否满足？

选择合适的开发语言和框架、组件

内存缓存和更新机制

异步执行避免阻塞、多核并发甚至GPU加速

多核与亲和

就近接入和跨运营商分布、CDN部署

高效的算法与数据结构

## 3、容错与高可用

冗余与部署计划（跨机房、跨城市？）

数据的类CRC校验

负载均衡与迁移

选举机制

柔性策略：产品策略柔性和技术上的柔性，例如带宽不足就把好友的实时状态信息去掉，登录只有验证密码环节是刚性的处理

进程监控与秒起：可以采用kubenetes / systemd的方案

轻重分离与故障隔离：一个案例：不重要业务的非法请求包把平台搞挂了，波及重要业务；某个特性老需要发布，导致重要的特性稳定性受到影响

过载保护：通过检查报文在请求队列里的延时决定丢弃请求包，避免过载；有克制的重试机制：后端服务应答成功率相当高的情况下，才允许有限额的重试

避免单点失效的影响：不可避免有单点的话，要评估单点失效的影响

方案本身的健壮性和简单粗暴

## 4、安全

数据安全：数据备份与恢复、异构、异地分布

密码学相关的协议和算法、信任和票据传递

业务安全：蜜罐、沙箱、防刷、防DDOS等机制，不展开，太专业了

## 5、可运维性

监控与告警、一览仪表盘：有详细的监控和告警，但同时要汇总出不多于3个指标（一个最好）能实时反应服务的状况

可追溯的日志：同一个请求在不同模块经过所产生的日志要能够串起来，海量的日志要能够方便查询。日志系统本身就是一个复杂的架构 

灰度发布：各种维度的灰度方式，最常见的是按机器灰度。识别出假灰度，识别出回滚的风险甚至不可回滚的问题

具备容量量化管理的能力、set化部署和快速的弹性伸缩：不只是应对大促等活动，快速部署通常也是应对故障最有效的方法，很多故障通过扩容可以快速解决。

容器化、web化界面方便操作

关键配置和版本的统一集中管理：代码以外的配置文件、运维说明文档也是导致故障的常见原因，避免分散在各员工的U盘和有鼻涕的半截A4纸上，统一管理起来。避免员工离职交接每次损失一半信息和运维能力。

安民告示：故障或者重大调整的时候，告知用户，稳定舆情

可观测、可视化：项目效果、系统的功用、流程执行的质量都应该是可观测的。例如工单的处理，有多少是自动化定位的，一线解决率是多少，耗时分布

## 6、开发高效高质量

选择一个成熟的开发运营框架，内置：

RPC、LBS、过载保护、基础监控与告警、熔断；

进入门槛低、代码可读性高

## 7、架构相关的团队能力

日常巡视、对运营情况了然于胸

发布规范和发布真正生效时值守

事故处理流程及事后总结和改进：提升团队能力的最佳时机

运营水平的量化追踪：例如使用可用性指标作为运营水平的考核目标

大促等重要事件的预案和常态化流程

没有经常验证的代码和流程都不可靠









