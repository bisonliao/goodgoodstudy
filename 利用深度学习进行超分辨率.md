# 引子 #
使用深度学习进行分类，是比较常见的一类应用，还有一类应用就是回归，对图像进行超分辨率，是回归中比较典型的例子

有比较多网络用于超分辨率，SRCNN是其中一个，本文记录作者通过SRCNN来体验深度学习的回归类应用的浅显过程。 SRCNN详细可见：

http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html

# 模型原理 #
SRCNN通过深度学习训练出来一个模型，该模型输入33\*33大小的（模糊）图片像素，输出21\*21大小的（清晰）图片像素。 

SRCNN对于一个低分辨率图像，先使用双三次（bicubic）插值将其放大到目标大小，再通过上述模型的计算，得到的结果作为高分辨率图像输出。

训练和测试用的标注样本也是这么来的： 一张清晰的图片O，通过先缩小再拉升的方式，获得一张模糊的图片B,提取模糊图片B的33\*33大小的区域作为模型的输入，提取清晰图片O的对应的21\*21的区域作为标注结果

SRCNN用到的网络比较简单，三层卷积，卷积核大小为9\*9、1\*1和5\*5。

相比分类，回归的损失函数是不一样的。回归用的是EuclideanLoss类型的损失函数，计算的是各个输出与标注之间的方差之和，分类用的是SOFTMAX_LOSS类型的损失函数。

# 模型训练 #

[官方训练包下载](http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html)

[另存一份的下载](code/srcnn/SRCNN.zip)

从SRCNN的官网下载caffe下的训练包，使用matlab执行generate_train.m和generate_test.m即可生成训练集和测试集，可以看到这两个脚本还算比较简单，就是扫描图片区域，生成标注好的样本，存储到HDF5里

	clear;close all;
	%% settings
	folder = 'Train\batch4';
	savepath = 'train4.h5';
	size_input = 33;  %%网络的输入大小
	size_label = 21;  %%网络的输出大小
	scale = 3;        %%超分倍数
	stride = 14;      %%扫描窗移动的步长

	%% initialization
	data = zeros(size_input, size_input, 1, 1);
	label = zeros(size_label, size_label, 1, 1);
	padding = abs(size_input - size_label)/2;
	count = 0;

	%% generate data
	filepaths = dir(fullfile(folder,'*.bmp'));
	   
	for i = 1 : length(filepaths)
		
		%%读取一张图片，灰度化，并将像素值转化为浮点
		image = imread(fullfile(folder,filepaths(i).name));
		image = rgb2ycbcr(image);
		image = im2double(image(:, :, 1));
		
		im_label = modcrop(image, scale); %%裁剪一下，使得宽高都是scale的倍数
		[hei,wid] = size(im_label);
		%%进行缩放，形成模糊的图片，
		im_input = imresize(imresize(im_label,1/scale,'bicubic'),[hei,wid],'bicubic');

		for x = 1 : stride : hei-size_input+1
			for y = 1 :stride : wid-size_input+1
				
				%%提取输入
				subim_input = im_input(x : x+size_input-1, y : y+size_input-1);
				%%提取标注结果，也就是模型的输出
				subim_label = im_label(x+padding : x+padding+size_label-1, y+padding : y+padding+size_label-1);

				count=count+1;
				%%写到内存数据结构里
				data(:, :, 1, count) = subim_input;
				label(:, :, 1, count) = subim_label;
			end
		end
	end

生成训练集和测试集后，即可执行caffe命令进行模型训练

# 模型的使用 #

[调用srcnn模型的c++例子](code/srcnn/sc.cpp)

[调用srcnn模型的makefile](code/srcnn/makefile)

过程中主要使用opencv的系列函数对图片进行操作，使用caffe的库函数使用训练好的模型。

节选一段代码：
	
    //对图片img的局部区域（i,j）进行超分，存储到img2里
	void super_resolution(boost::shared_ptr<Net<float> > net,
			cv::Mat & img,  cv::Mat & img2,
			int i, int j)
	{
			float data_input[input_size][input_size];

			//挨个像素填写输入项
			int sub_i, sub_j;
			for (sub_i = 0; sub_i < input_size; ++sub_i)
			{
					for (sub_j = 0; sub_j < input_size; ++sub_j)
					{
							data_input[sub_i][sub_j] = (float)(img.at<uchar>(i+sub_i, j+sub_j));
					}
			}

			caffe_forward(net, (float*)data_input);//网络向前传播，计算出输出
			int index = get_blob_index(net, "conv3");//获取conv3层的输出值
			boost::shared_ptr<Blob<float> > blob = net->blobs()[index];
			unsigned int num_data = blob->count(); 
			const float *blob_ptr = (const float *) blob->cpu_data();

			//逐项写入到img2
			for (sub_i = 0; sub_i < label_size; ++sub_i)
			{
					for (sub_j = 0; sub_j < label_size; ++sub_j)
					{
							img2.at<uchar>(i+sub_i, j+sub_j) = (unsigned char)(blob_ptr[sub_i*label_size+sub_j]);
					}
			}

	}


代码比较简单，就不赘述，直接下载上面的代码看即可

下面是作者的效果图，可以看出效果不太好，相比bicubic，没有明显的优势。应该是我哪里姿势不对

![效果图](img/srcnn/srcnn1.png)

# tips #

* 如果用于训练的图片比较多，matlab脚本生成的HDF5文件会比较大，可以分批生成多个HDF5文件，caffe支持在train.txt和 test.txt文件里指定多个HDF5文件

* 如果不想在windows下使用matlab，可以尝试在linux下安装octave软件（一个比较有名的数学工具，兼容matlab脚本），安装的时候需要装全octave的pkg，在opensuse下，用yum search all octave命令可以找到所有的包，全部都安装，也可以在octave交互模式下输入 pkg install -forge <pkgname>的方式来安装。 但是：octave执行起来真的好慢好慢，对于大量的图片处理是不合适的

* 有高手同事说，训练集准备，需要做一下扩充，把一些图片进行变换（90\*n的旋转、0.6~0.9倍的缩小两者的组合）后补充到Train目录下再用generate_train.m脚本处理，否则训练出来的模型效果不好，只是下采样的逆。 我直观上不太能理解，但我先记住这个结论吧。

# 几个概念 #

神经网络里，有几个概念：

* **batch\_size**：分训练的batch\_size和测试的batch\_size。训练/测试的时候，不是每次一个样本，也不是每次都把完整训练/测试集都拿来测试/训练，而是一次取batch\_size个样本，来进行一次传播（一次传播=一次前向传播+一次后向传播）。 batch\_size越大，效率约高，但占用内存越大。

* **前向传播**：取出batch\_size个样本，对每个样本输入**X**  , 经过与各层网络的weight、bias值乘加运算，得到**Y**，与样本标注的分类/回归值**YY** 对比获得差值**d** ，batch\_size个样本的差值**d** 加起来，得到损失函数**L**

* **后向传播**：损失函数**L**是**Y**和**YY**的函数，而**Y**是最后一层weight和bias参数的函数，也就是说损失函数是最后一层weight和bias参数的函数，要使得损失函数最小，就求偏导的方式，找到损失函数的梯度，微调weight和bias参数； 同理，函数关系继续往上一层网络的weight和bias传播，可以用梯度下降的方式调整倒数第二层的weight和bias参数，如此反复，最后完成第一层网络的weight和bias参数的微调，这是一次后向传播

* **iteration**: 输入batch\_size个训练样本，完成一次前向传播+后向传播，就是一次iteration

* **epoch**： 执行n次iteration，将训练样本恰好全部的训练一次，叫做一次epoch，通常我们一次epoch就做一次测试，所以通常solver.prototxt文件里的test\_interval乘以训练的batch\_size就等于训练集的大小，而test\_iter乘以测试的batch\_size就等于测试集的大小

* **max\_iter**： 通过solver.prototxt文件里的max_iter参数，可以指定最多训练多少个iteration才终止

* **激活函数**: 如果不引入sigmoid这样的激活函数，那么网络中的多个层实际上等同于只有一层，因为最后层的某项输出就等于w1\*x1+w2\*x2+...+w0，各层的参数会发生退化与合并。 同时可以注意到：激活函数的引入，使得向后传播求变得复杂了，而且不同激活函数的导数值对后向传播效率有影响。

关于激活函数以及其对后向传播的影响，这里有篇文章写的比较好：

https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247483977&idx=1&sn=401b211bf72bc70f733d6ac90f7352cc&chksm=fdb69fdecac116c81aad9e5adae42142d67f50258106f501af07dc651d2c1473c52fad8678c3&scene=21#wechat_redirect

摘取其中的几段：

![](img/srcnn/activation_func1.jpg)

激活函数的要求：

1. 非线性
2. 万能逼近定理
3. 处处可导：满足后向传播时候链式求导的需要
4. 导数绝对值不能太大，也不能太小，避免引起梯度消失和梯度爆炸

![](img/srcnn/activation_func2.jpg)


# 梯度下降法 #

以一个线性回归问题为例:

N个实例组成的训练集(x1, x2， y)[N], 训练出一组参数a,b,c，使得输入x1,x2,  计算y'=a*x1 + b*x2 +c， y'与y误差尽量小。

定义损失函数为 J = 1/N * ∑(y-y')^2 ， 求使得损失函数最小的参数a,b,c， 可以使用梯度下降法：

1. 随机选取向量 **w(0)** = (w1, w2, w3)作为初始值
2. 根据梯度公式 **▽J(w)** = ( ∂J/∂w1, ∂J/∂w2, ∂J/∂w2) ，代入当前的(w1, w2, w3)值，即获得当前位置的梯度
3. 沿着梯度下降的方向前进一小步，计算得到新的**w**。即 **w(n+1)** = **w(n)** - step * **▽J(w)**
4. 如此反复，直到收敛。

下面用mathematica代码演示：

先构建一组训练集：

	ClearAll["Global`*"];
	a = 1;
	b = 2;
	c = 3;
	NUM = 20;
	y[x1_, x2_] = a*x1 + b*x2 + c;
	x1arr = Table[RandomReal[{-5, 5}], {i, 1, NUM}];
	x2arr = Table[RandomReal[{-10, 10}], {i, 1, NUM}];
	trainset = Table[0, {i, 1, NUM}];
	labels = Table[0, {i, 1, NUM}];
	For[i = 1, i <= NUM, i++,
	  labels[[i]] = y[x1arr[[i]], x2arr[[i]]] + RandomReal[{-0.1, 0.1}];
	  trainset[[i]] = {x1arr[[i]], x2arr[[i]], labels[[i]] }
	  
	  ];

将参数都初始化为1，然后定义损失函数，并求梯度公式、代入参数计算当前的梯度值

	w1 = 1;
	w2 = 1;
	w3 = 1;
	stepsz = 0.001;
	loss = Sum[(s1*x1arr[[i]] + s2*x2arr[[i]] + s3 - labels[[i]])^2 / 
	    NUM, {i, 1, NUM}];
	Do[
	  g1 = D[loss, s1] /. {s1 -> w1, s2 -> w2, s3 -> w3};
	  g2 = D[loss, s2] /. {s1 -> w1, s2 -> w2, s3 -> w3};
	  g3 = D[loss, s3] /. {s1 -> w1, s2 -> w2, s3 -> w3};
	  
	  w1 = w1 - g1*stepsz;
	  w2 = w2 - g2*stepsz;
	  w3 = w3 - g3*stepsz
	  ,
	  {k, 1, 2000}];
	Print[{w1, w2, w3}];

得到正确的输出为：

	{1.01699,2.00054,2.90552}
