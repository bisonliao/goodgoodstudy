# 1.引子 #
使用深度学习进行分类，是比较常见的一类应用，还有一类应用就是回归，对图像进行超分辨率，是回归中比较典型的例子

有比较多网络用于超分辨率，SRCNN是其中一个，本文记录作者通过SRCNN来体验深度学习的回归类应用的浅显过程。 SRCNN详细可见：

http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html

# 2.模型原理 #
SRCNN通过深度学习训练出来一个模型，该模型输入33\*33大小的（模糊）图片像素，输出21\*21大小的（清晰）图片像素。 

SRCNN对于一个低分辨率图像，先使用双三次（bicubic）插值将其放大到目标大小，再通过上述模型的计算，得到的结果作为高分辨率图像输出。

训练和测试用的标注样本也是这么来的： 一张清晰的图片O，通过先缩小再拉升的方式，获得一张模糊的图片B,提取模糊图片B的33\*33大小的区域作为模型的输入，提取清晰图片O的对应的21\*21的区域作为标注结果

SRCNN用到的网络比较简单，三层卷积，卷积核大小为9\*9、1\*1和5\*5。

相比分类，回归的损失函数是不一样的。回归用的是EuclideanLoss类型的损失函数，计算的是各个输出与标注之间的方差之和，分类用的是SOFTMAX_LOSS类型的损失函数。

# 3.模型训练 #

[官方训练包下载](http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html)

[另存一份的下载](code/srcnn/SRCNN.zip)

从SRCNN的官网下载caffe下的训练包，使用matlab执行generate_train.m和generate_test.m即可生成训练集和测试集，可以看到这两个脚本还算比较简单，就是扫描图片区域，生成标注好的样本，存储到HDF5里

	clear;close all;
	%% settings
	folder = 'Train\batch4';
	savepath = 'train4.h5';
	size_input = 33;  %%网络的输入大小
	size_label = 21;  %%网络的输出大小
	scale = 3;        %%超分倍数
	stride = 14;      %%扫描窗移动的步长
	
	%% initialization
	data = zeros(size_input, size_input, 1, 1);
	label = zeros(size_label, size_label, 1, 1);
	padding = abs(size_input - size_label)/2;
	count = 0;
	
	%% generate data
	filepaths = dir(fullfile(folder,'*.bmp'));
	   
	for i = 1 : length(filepaths)
		
		%%读取一张图片，灰度化，并将像素值转化为浮点
		image = imread(fullfile(folder,filepaths(i).name));
		image = rgb2ycbcr(image);
		image = im2double(image(:, :, 1));
		
		im_label = modcrop(image, scale); %%裁剪一下，使得宽高都是scale的倍数
		[hei,wid] = size(im_label);
		%%进行缩放，形成模糊的图片，
		im_input = imresize(imresize(im_label,1/scale,'bicubic'),[hei,wid],'bicubic');
	
		for x = 1 : stride : hei-size_input+1
			for y = 1 :stride : wid-size_input+1
				
				%%提取输入
				subim_input = im_input(x : x+size_input-1, y : y+size_input-1);
				%%提取标注结果，也就是模型的输出
				subim_label = im_label(x+padding : x+padding+size_label-1, y+padding : y+padding+size_label-1);
	
				count=count+1;
				%%写到内存数据结构里
				data(:, :, 1, count) = subim_input;
				label(:, :, 1, count) = subim_label;
			end
		end
	end

生成训练集和测试集后，即可执行caffe命令进行模型训练

# 4.模型的使用 #

[调用srcnn模型的c++例子](code/srcnn/sc.cpp)

[调用srcnn模型的makefile](code/srcnn/makefile)

过程中主要使用opencv的系列函数对图片进行操作，使用caffe的库函数使用训练好的模型。

节选一段代码：
	
    //对图片img的局部区域（i,j）进行超分，存储到img2里
    void super_resolution(boost::shared_ptr<Net<float> > net,
    		cv::Mat & img,  cv::Mat & img2,
    		int i, int j)
    {
    		float data_input[input_size][input_size];
    
    		//挨个像素填写输入项
    		int sub_i, sub_j;
    		for (sub_i = 0; sub_i < input_size; ++sub_i)
    		{
    				for (sub_j = 0; sub_j < input_size; ++sub_j)
    				{
    						data_input[sub_i][sub_j] = (float)(img.at<uchar>(i+sub_i, j+sub_j));
    				}
    		}
    
    		caffe_forward(net, (float*)data_input);//网络向前传播，计算出输出
    		int index = get_blob_index(net, "conv3");//获取conv3层的输出值
    		boost::shared_ptr<Blob<float> > blob = net->blobs()[index];
    		unsigned int num_data = blob->count(); 
    		const float *blob_ptr = (const float *) blob->cpu_data();
    
    		//逐项写入到img2
    		for (sub_i = 0; sub_i < label_size; ++sub_i)
    		{
    				for (sub_j = 0; sub_j < label_size; ++sub_j)
    				{
    						img2.at<uchar>(i+sub_i, j+sub_j) = (unsigned char)(blob_ptr[sub_i*label_size+sub_j]);
    				}
    		}
    
    }


代码比较简单，就不赘述，直接下载上面的代码看即可

下面是作者的效果图，可以看出效果不太好，相比bicubic，没有明显的优势。应该是我哪里姿势不对

![效果图](img/srcnn/srcnn1.png)

# 5.tips #

* 如果用于训练的图片比较多，matlab脚本生成的HDF5文件会比较大，可以分批生成多个HDF5文件，caffe支持在train.txt和 test.txt文件里指定多个HDF5文件
* 如果不想在windows下使用matlab，可以尝试在linux下安装octave软件（一个比较有名的数学工具，兼容matlab脚本），安装的时候需要装全octave的pkg，在opensuse下，用yum search all octave命令可以找到所有的包，全部都安装，也可以在octave交互模式下输入 pkg install -forge <pkgname>的方式来安装。 但是：octave执行起来真的好慢好慢，对于大量的图片处理是不合适的
* 有高手同事说，训练集准备，需要做一下扩充，把一些图片进行变换（90\*n的旋转、0.6~0.9倍的缩小两者的组合）后补充到Train目录下再用generate_train.m脚本处理，否则训练出来的模型效果不好，只是下采样的逆。 我直观上不太能理解，但我先记住这个结论吧。
* 基于已有的模型做精细化调教（finetune），使用命令行参数--weights=....caffemodel文件，如果是训练中断后需要做“断点续练”，那么使用命令行参数--snapshot=....solverstat文件

