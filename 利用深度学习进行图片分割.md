# 利用深度学习进行图片语义分割

## 1、问题提出

图片语义分割，就是自动分割并识别出图片中的各部分内容。类似下面图中识别出人体、动物、球拍等。

![这里有张图片](img/FCN/fcn.png)

用到的技术之一是全卷积网络（FCN），顾名思义，就是这个网络是全部由卷积层组成的。

FCN是CNN演变而来的，CNN最典型的一个用法是用于图片分类，最后的几层通常是全连接层和SoftMax层，将图片进过卷积层提取到的特征经过计算后，转化为N X 1的向量，向量的每个元素对应一个分类的概率。类似下面图中的上面部分最后对1000个分类进行概率判断：

![这里有张图片](img/FCN/fcn2.jpg)

FCN通过deconvolution层上采样，相当于对输入图片的每个像素都进行分类，也就是输入一张 Ch X W X H的图片，输出一个 N X W X H的结果， N是分类总个数，像素位置一一对应。

deconvolution可以理解为反向的卷积层，下游输出BLOB的尺寸的推导，与卷积层刚好是反过来的。例如下图：

![这里有张图片](img/FCN/fcn3.jpg)

来自上层的输入尺寸 7 X 7， 卷积核大小是4，步进大小是2，那么输出尺寸是多少呢？  反过来推导：输入尺寸是多少，经过一个核大小为4步进大小是2的卷积核，才能输出7 X 7 呢？ 很容易计算得到是16 X 16。

FCN的

[详细的论文](https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html)

[官方github代码](https://github.com/shelhamer/fcn.berkeleyvision.org)

## 2、试验

### 2.1 试验数据的获取和整理

我使用的是coco数据集中的train2014数据包和对应的标注，一开始简单点：只做二分类 ：区分前景和背景，把coco数据集中的segmentation标注的多边形区域都认为是前景，其他区域认为是背景。生成的训练集的每个像素的label为0/1二分类。

[coco数据集](http://cocodataset.org/)

先用python脚本把标注信息整理成一个文本文件，每行的格式为

```
文件名 分割信息的数组
```

然后用下面的代码处理成HDF5文件或者是单独的图片，该程序主要用到了jsoncpp  opencv hdf5等库。

[生成训练集的代码](code/fcn/ConvertRegionToClass.cpp)

摘要一些片段如下：

```c
int segm_num = root.size();// how many segm in this image
for (int i = 0;  i < segm_num; ++i)
{
	int partnum = root[i].size(); // how many part in this segm

	for (int j = 0; j < partnum; ++j)
	{
		int coornum = root[i][j].size();//how many coordinary in this part
		static Point points[1][1024];
		int k;
		for (k = 0; k < coornum && k < 2048; k+=2)
		{
			int x = root[i][j][k].asInt();
			int y = root[i][j][k+1].asInt();
			points[0][k / 2] = Point(x, y);
		}
		
		const Point* pts[] = { points[0] };
		int npts[1];
		npts[0] = k / 2;
		//polylines(img, pts, npts, 1, true, Scalar(255), 3);
		fillPoly(dest, pts, npts, 1, Scalar(255));
		//polylines(dest, pts, npts, 1, true, Scalar(255), 3);
	}

}
```
### 2.2 使用官方的pycaffe接口的方式进行训练

fcn官方github上代码是使用caffe的python接口写代码来训练的方式，而不是我常见的caffe.exe train命令行的方式。

官方的代码和文档几乎没有什么整理，以至于csdn上大量的博客写怎么怎么搞定这件事情的，这些作者通常会悲催的弄上两三个星期。

[这篇博客记录得很详细](https://blog.csdn.net/jiongnima/article/details/78549326)

下载了github上的zip包，我照着博客指引跑通了，细节不赘述了，记录几个要点：

1. 用了python类型的数据层来输入数据和标注，voc_layers.py、siftflow_layers.py、pascalcontext_layers.py分别应对不同的开源数据集。这些python层通常有两个类，分别处理输入数据和输入标签
2. voc_xxx、siftflow_xxx、pascalcontent_xxx等子目录，是根据开源数据集和上采样的倍数区分的，大同小异，都是做语义分割，进入其中一个子目录开始折腾就好。有耐心的解决solver.py执行中遇到的问题即可
3. fcn训练是很耗资源的，我的小机器从0开始训练基本上没有什么进展，所以要基于一定的基础做finetune，子目录下的caffemodel-url文件给出了一个现成的用来finetune的模型，比较大，要有耐心下载
4. 把infer.py  score.py等这些被引用的python代码都拷贝到你想要折腾的那个子目录，把训练集目录对应的路径相关的代码有耐心的改改
5. solver.prototxt文件里的base_lr改为1e-8，会比较快收敛

我用了三万张图片来训练，跑了10来个小时后，loss从4下降到1左右不收敛了，测试的准确率为80%。 对于一个二分类问题来说，这个准确率太低，比瞎蒙好不了多少。mean accuracy是什么鬼？

![这里有张图片](img/FCN/fcn4.jpg)

### 2.3 使用我熟悉的命令行方式训练

其实我是先用命令行方式来训练的，只是后来不收敛了，就开始怀疑人生，然后找到了上面提到的csdn上的那篇博客，又尝试用python方式。

博客中提到的什么三次插值初始化是不是关键点，我有点怀疑。因为其实大家都是在同一个现有模型的基础上finetune，那某一层的额外的初始化还重要吗？

我用的是HDF5文件作为数据输入类型。用到的prototxt文件在下面目录

[存放网络定义文件的目录](code/myfcn)

[finetune的基石模型](http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel)

未完待续

## 9、题外话

1. python真的很强大，同样是处理一个很大的json文件（来自coco数据集），我一开始用jsonc库（号称最好用的c语言下的json库），加载文件失败；改用java语言，提示虚拟机栈空间不够，调整虚拟机参数也没有解决。 python轻松搞定
2. jsoncpp/rapidjson/jsonc等好几个库，下载到windows下从源代码开始构建，步骤是
   1. 在库展开的目录下建一个build子目录
   2. cd到build子目录，执行cmake ..
   3. 然后就会看到build子目录里有个visualstudio解决方案，用vs2015打开它就能编译好
3. 但上面cmake这样搞出来的，默认是x86不是x64的，与x64的项目用不到一块。咋办？cmake的时候加一个选项即可： -G ' Visual Studio 14 win64'

